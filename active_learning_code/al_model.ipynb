{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f57f121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "df49789a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.00080725 0.00279541 ... 0.0070593  0.00716106 0.00549977]\n",
      " [0.00080725 0.         0.00198602 ... 0.0062452  0.00634686 0.0046874 ]\n",
      " [0.00279541 0.00198602 0.         ... 0.00553359 0.00563517 0.00397732]\n",
      " ...\n",
      " [0.0070593  0.0062452  0.00553359 ... 0.         0.00010086 0.00168274]\n",
      " [0.00716106 0.00634686 0.00563517 ... 0.00010086 0.         0.00178381]\n",
      " [0.00549977 0.0046874  0.00397732 ... 0.00168274 0.00178381 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Import genetic distance matrix IDs\n",
    "with open('../epidemic_simulation_data/genetic_distance_matrices/genetic_distance_matrix_names.txt', 'r') as file:\n",
    "    matrix_ids = file.read().splitlines()\n",
    "\n",
    "# Import pairwise genetic distance matrix\n",
    "pandas2ri.activate()\n",
    "\n",
    "## Load the RData file\n",
    "ro.r['load']('../epidemic_simulation_data/genetic_distance_matrices/genetic_distance_matrix.RData')\n",
    "\n",
    "## Access genetic distance matrix\n",
    "gdist_seqs_dm = ro.r['gdist_seqs_dm']\n",
    "\n",
    "## Check if it's a dist object and convert it to a matrix in R\n",
    "if isinstance(gdist_seqs_dm, ro.Vector):\n",
    "    gdist_seqs_dm_matrix = ro.r.as_matrix(gdist_seqs_dm)\n",
    "\n",
    "    ### Convert the R matrix to a NumPy array\n",
    "    gendist_matrix = np.array(gdist_seqs_dm_matrix)\n",
    "else:\n",
    "    ### Directly convert to a NumPy array if it's already in an appropriate format\n",
    "    gendist_matrix = np.array(gdist_seqs_dm)\n",
    "\n",
    "## Confirm object creation\n",
    "print(gendist_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d33c1be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id       date collection_location  new_cases  mobility  \\\n",
      "7187        seq_0 2020-10-13            domestic          1     -0.01   \n",
      "7189       seq_37 2020-08-28            domestic         19     -0.01   \n",
      "7213      seq_661 2020-07-23            domestic        184     -0.01   \n",
      "89      seq_10057 2020-07-11         intl_source        515      0.01   \n",
      "3941    seq_41495 2020-05-03         intl_source       8888      0.01   \n",
      "...           ...        ...                 ...        ...       ...   \n",
      "1261   seq_126100 2020-05-28         intl_source       5271      0.01   \n",
      "4273    seq_48219 2020-04-30         intl_source       8844      0.01   \n",
      "10071  seq_144133 2020-05-18            domestic       9947     -0.01   \n",
      "2009   seq_142575 2020-05-19         intl_source       6847      0.01   \n",
      "11168  seq_160664 2020-05-12            domestic      12229     -0.01   \n",
      "\n",
      "       sequencing_intensity travel_history  date_numeric  \n",
      "7187               1.000000      no_travel           273  \n",
      "7189               0.210526      no_travel           227  \n",
      "7213               0.114130      no_travel           191  \n",
      "89                 0.099029  international           179  \n",
      "3941               0.094397  international           110  \n",
      "...                     ...            ...           ...  \n",
      "1261               0.097704  international           135  \n",
      "4273               0.100633  international           107  \n",
      "10071              0.097517      no_travel           125  \n",
      "2009               0.097415  international           126  \n",
      "11168              0.101971      no_travel           119  \n",
      "\n",
      "[16068 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import and process data frames\n",
    "sampling_pool_df = pd.read_csv('../epidemic_simulation_data/sampling_pool.csv')\n",
    "domestic_pool_df = pd.read_csv('../epidemic_simulation_data/domestic_pool.csv')\n",
    "\n",
    "## Merge the data frames on 'id' to combine all features and labels for each observation\n",
    "combined_df = pd.merge(sampling_pool_df, domestic_pool_df, on=['id', 'date', 'collection_location', 'new_cases', 'mobility', 'sequencing_intensity'], how='outer')\n",
    "\n",
    "## Replace NaN values in 'travel_history' column\n",
    "combined_df['travel_history'] = combined_df['travel_history'].fillna('international')\n",
    "\n",
    "## Convert 'date' to a numerical feature, e.g., days since the first date in the dataset\n",
    "combined_df['date'] = pd.to_datetime(combined_df['date'])\n",
    "combined_df['date_numeric'] = (combined_df['date'] - combined_df['date'].min()).dt.days\n",
    "\n",
    "\n",
    "## Rearrange by 'id'\n",
    "### Use pd.Categorical to impose the order of 'matrix_ids' on the combined DataFrame\n",
    "combined_df['id_ordered'] = pd.Categorical(\n",
    "    combined_df['id'], categories=matrix_ids, ordered=True)\n",
    "\n",
    "### Sort the combined DataFrame by this new 'id_ordered' column\n",
    "combined_df = combined_df.sort_values('id_ordered')\n",
    "\n",
    "### Drop the temporary 'id_ordered' column\n",
    "combined_df = combined_df.drop(columns=['id_ordered'])\n",
    "\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7464be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering, step A - prepare features from data frames\n",
    "## Features include 'new_cases', 'sequencing_intensity', 'mobility', 'date_numeric',\n",
    "## and genetic distances.\n",
    "\n",
    "## Prepare features and labels\n",
    "features = combined_df[['new_cases', 'sequencing_intensity', 'mobility', 'date_numeric']].values\n",
    "\n",
    "## Add distance features here as needed, depending on the structure of your distance matrix\n",
    "labels = combined_df['travel_history']  ### Assuming this column contains X, Y, and possibly A labels\n",
    "\n",
    "## Convert labels to a numeric format for machine learning: 0 for international, 1 for travel, and\n",
    "## 2 for no_travel (unlabeled)\n",
    "numeric_labels = labels.map({'international': 0, 'travel': 1, 'no_travel': 2}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "00cb6d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering, step B - incorporate genetic distances as features\n",
    "## Approach 1: we'll use the distance to the nearest reference observation as a feature\n",
    "min_distance_to_reference = np.min(gendist_matrix, axis=1)  ### Minimum distance for each observation\n",
    "\n",
    "## Incorporate this distance feature into your existing features\n",
    "features = np.hstack([features, min_distance_to_reference.reshape(-1, 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "74c8d7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy: 0.9225260416666666\n"
     ]
    }
   ],
   "source": [
    "# AL model setup and training - minimum genetic distances\n",
    "## Initial split: separate labeled (international samples and samples with travel history) from unlabeled\n",
    "## (no travel history) data\n",
    "labeled_indices = np.where(numeric_labels != 2)[0]\n",
    "unlabeled_indices = np.where(numeric_labels == 2)[0]\n",
    "\n",
    "# You would use 'features_with_distance' in place of 'features' for training and predictions\n",
    "X_labeled_with_distance = features[labeled_indices]\n",
    "X_unlabeled_with_distance = features[unlabeled_indices]\n",
    "\n",
    "## Second split: separate labeled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_labeled_with_distance, y_labeled, test_size=0.2, random_state=42)\n",
    "\n",
    "## Train initial model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate initial model\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Initial accuracy: {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "79abfe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active Learning Loop conditions\n",
    "n_iterations = 50  ### Define the number of iterations for the active learning loop\n",
    "\n",
    "def query_for_label(index):\n",
    "    ## Placeholder for your label querying mechanism\n",
    "    ## This function should return the true label for the sample identified by `index`\n",
    "    return np.random.randint(0, 2)  ### Example: simulate obtaining a label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3fc9927a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, accuracy: 0.9225260416666666\n",
      "Iteration 2, accuracy: 0.9225260416666666\n",
      "Iteration 3, accuracy: 0.9225260416666666\n",
      "Iteration 4, accuracy: 0.9225260416666666\n",
      "Iteration 5, accuracy: 0.9225260416666666\n",
      "Iteration 6, accuracy: 0.9225260416666666\n",
      "Iteration 7, accuracy: 0.9225260416666666\n",
      "Iteration 8, accuracy: 0.9225260416666666\n",
      "Iteration 9, accuracy: 0.9225260416666666\n",
      "Iteration 10, accuracy: 0.9225260416666666\n",
      "Iteration 11, accuracy: 0.9225260416666666\n",
      "Iteration 12, accuracy: 0.9225260416666666\n",
      "Iteration 13, accuracy: 0.9225260416666666\n",
      "Iteration 14, accuracy: 0.9225260416666666\n",
      "Iteration 15, accuracy: 0.9225260416666666\n",
      "Iteration 16, accuracy: 0.9225260416666666\n",
      "Iteration 17, accuracy: 0.9225260416666666\n",
      "Iteration 18, accuracy: 0.9225260416666666\n",
      "Iteration 19, accuracy: 0.9225260416666666\n",
      "Iteration 20, accuracy: 0.9225260416666666\n",
      "Iteration 21, accuracy: 0.9225260416666666\n",
      "Iteration 22, accuracy: 0.9225260416666666\n",
      "Iteration 23, accuracy: 0.9225260416666666\n",
      "Iteration 24, accuracy: 0.9225260416666666\n",
      "Iteration 25, accuracy: 0.9225260416666666\n",
      "Iteration 26, accuracy: 0.9225260416666666\n",
      "Iteration 27, accuracy: 0.9225260416666666\n",
      "Iteration 28, accuracy: 0.9225260416666666\n",
      "Iteration 29, accuracy: 0.9225260416666666\n",
      "Iteration 30, accuracy: 0.9225260416666666\n",
      "Iteration 31, accuracy: 0.9225260416666666\n",
      "Iteration 32, accuracy: 0.9225260416666666\n",
      "Iteration 33, accuracy: 0.9225260416666666\n",
      "Iteration 34, accuracy: 0.9225260416666666\n",
      "Iteration 35, accuracy: 0.9225260416666666\n",
      "Iteration 36, accuracy: 0.9225260416666666\n",
      "Iteration 37, accuracy: 0.9225260416666666\n",
      "Iteration 38, accuracy: 0.9225260416666666\n",
      "Iteration 39, accuracy: 0.9225260416666666\n",
      "Iteration 40, accuracy: 0.9225260416666666\n",
      "Iteration 41, accuracy: 0.9225260416666666\n",
      "Iteration 42, accuracy: 0.9225260416666666\n",
      "Iteration 43, accuracy: 0.9225260416666666\n",
      "Iteration 44, accuracy: 0.9225260416666666\n",
      "Iteration 45, accuracy: 0.9225260416666666\n",
      "Iteration 46, accuracy: 0.9225260416666666\n",
      "Iteration 47, accuracy: 0.9225260416666666\n",
      "Iteration 48, accuracy: 0.9225260416666666\n",
      "Iteration 49, accuracy: 0.9225260416666666\n",
      "Iteration 50, accuracy: 0.9225260416666666\n"
     ]
    }
   ],
   "source": [
    "# Active Learning Loop - minimum genetic distances\n",
    "for iteration in range(n_iterations):\n",
    "    X_unlabeled = features[unlabeled_indices]\n",
    "    probs = model.predict_proba(X_unlabeled_with_distance) ### Use minimum genetic distance as feature\n",
    "    \n",
    "    uncertainty = np.max(probs, axis=1)\n",
    "    query_idx = np.argmax(uncertainty)\n",
    "    \n",
    "    true_label = query_for_label(unlabeled_indices[query_idx])\n",
    "    \n",
    "    X_train = np.vstack([X_train, X_unlabeled_with_distance[query_idx]]) ### Use minimum genetic distance as feature\n",
    "    y_train = np.append(y_train, true_label)\n",
    "    \n",
    "    unlabeled_indices = np.delete(unlabeled_indices, query_idx)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Iteration {iteration + 1}, accuracy: {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b059dd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id predicted_label\n",
      "0        seq_16        unlinked\n",
      "1        seq_60        unlinked\n",
      "2       seq_144        unlinked\n",
      "3       seq_228        unlinked\n",
      "4       seq_263        unlinked\n",
      "...         ...             ...\n",
      "8333   seq_9961        unlinked\n",
      "8334  seq_99716        unlinked\n",
      "8335  seq_99785        unlinked\n",
      "8336  seq_99841        unlinked\n",
      "8337  seq_99876        unlinked\n",
      "\n",
      "[8338 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Predict labels of unlabeled (no travel history) sequences\n",
    "\n",
    "## Extract features for unlabeled data\n",
    "X_unlabeled = features[unlabeled_indices]\n",
    "\n",
    "## Use the trained model to predict the labels of the unlabeled data\n",
    "predicted_labels = model.predict(X_unlabeled)\n",
    "\n",
    "## This task is a binary classification exercise which identifies unlabeled sequences as either\n",
    "## 'linked to the source' or 'not linked to the source'.\n",
    "## The model will output 0 (unlinked) or 1 (linked).\n",
    "\n",
    "## For illustration, let's map 0 to 'A' and 1 to 'X' (though in your case, 'Y' predictions remain 'Y')\n",
    "predicted_labels_mapped = np.where(predicted_labels == 0, 'unlinked', 'linked')\n",
    "\n",
    "## Attach these predictions back to your original dataset\n",
    "ids_unlabeled = combined_df.loc[unlabeled_indices, 'id'].values\n",
    "\n",
    "predicted_df = pd.DataFrame({\n",
    "    'id': ids_unlabeled,\n",
    "    'predicted_label': predicted_labels_mapped\n",
    "})\n",
    "\n",
    "print(predicted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b3017c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of linked observations (predicted as 'X'): 177\n",
      "Number of unlinked observations (remaining as 'Y'): 8161\n"
     ]
    }
   ],
   "source": [
    "# Summarise predicted labels\n",
    "## Count the number of linked and unlinked observations in the predicted labels\n",
    "linked_count = (predicted_df['predicted_label'] == 'linked').sum()\n",
    "unlinked_count = (predicted_df['predicted_label'] == 'unlinked').sum()\n",
    "\n",
    "print(f\"Number of linked observations (predicted as 'with travel history'): {linked_count}\")\n",
    "print(f\"Number of unlinked observations (remaining as 'without travel history'): {unlinked_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0cfa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
