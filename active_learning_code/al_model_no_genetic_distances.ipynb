{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbc21bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import genetic distance matrix IDs\n",
    "with open('../epidemic_simulation_data/genetic_distance_matrices/genetic_distance_matrix_names.txt', 'r') as file:\n",
    "    matrix_ids = file.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82f4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and process data frames\n",
    "sampling_pool_df = pd.read_csv('../epidemic_simulation_data/sampling_pool.csv')\n",
    "domestic_pool_df = pd.read_csv('../epidemic_simulation_data/domestic_pool.csv')\n",
    "\n",
    "## Merge the data frames on 'id' to combine all features and labels for each observation\n",
    "combined_df = pd.merge(sampling_pool_df, domestic_pool_df, on=['id', 'date', 'collection_location', 'new_cases', 'mobility', 'sequencing_intensity'], how='outer')\n",
    "\n",
    "## Replace NaN values in 'travel_history' column\n",
    "combined_df['travel_history'] = combined_df['travel_history'].fillna('international')\n",
    "\n",
    "## Convert 'date' to a numerical feature, e.g., days since the first date in the dataset\n",
    "combined_df['date'] = pd.to_datetime(combined_df['date'])\n",
    "combined_df['date_numeric'] = (combined_df['date'] - combined_df['date'].min()).dt.days\n",
    "\n",
    "\n",
    "## Rearrange by 'id'\n",
    "### Use pd.Categorical to impose the order of 'matrix_ids' on the combined DataFrame\n",
    "combined_df['id_ordered'] = pd.Categorical(\n",
    "    combined_df['id'], categories=matrix_ids, ordered=True)\n",
    "\n",
    "### Sort the combined DataFrame by this new 'id_ordered' column\n",
    "combined_df = combined_df.sort_values('id_ordered')\n",
    "\n",
    "### Drop the temporary 'id_ordered' column\n",
    "combined_df = combined_df.drop(columns=['id_ordered'])\n",
    "\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b372e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering - prepare features from data frames\n",
    "## Features include 'new_cases', 'sequencing_intensity', 'mobility', 'date_numeric',\n",
    "## and genetic distances.\n",
    "\n",
    "## Prepare features and labels\n",
    "features = combined_df[['new_cases', 'sequencing_intensity', 'mobility', 'date_numeric']].values\n",
    "\n",
    "## Add distance features here as needed, depending on the structure of your distance matrix\n",
    "labels = combined_df['travel_history']  ### Assuming this column contains X, Y, and possibly A labels\n",
    "\n",
    "## Convert labels to a numeric format for machine learning: 0 for international, 1 for travel, and\n",
    "## 2 for no_travel (unlabeled)\n",
    "numeric_labels = labels.map({'international': 0, 'travel': 1, 'no_travel': 2}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b341d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AL model setup and training - no genetic distances\n",
    "## Initial split: separate labeled (international samples and samples with travel history) from unlabeled\n",
    "## (no travel history) data\n",
    "labeled_indices = np.where(numeric_labels != 2)[0]\n",
    "unlabeled_indices = np.where(numeric_labels == 2)[0]\n",
    "\n",
    "X_labeled = features[labeled_indices]\n",
    "y_labeled = numeric_labels[labeled_indices]\n",
    "\n",
    "## Second split: separate labeled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_labeled, y_labeled, test_size=0.2, random_state=42)\n",
    "\n",
    "## Train initial model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate initial model\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Initial accuracy: {accuracy_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7295e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active Learning Loop conditions\n",
    "n_iterations = 50  ### Define the number of iterations for the active learning loop\n",
    "\n",
    "def query_for_label(index):\n",
    "    ## Placeholder for your label querying mechanism\n",
    "    ## This function should return the true label for the sample identified by `index`\n",
    "    return np.random.randint(0, 2)  ### Example: simulate obtaining a label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac48da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active Learning Loop - no genetic distances\n",
    "for iteration in range(n_iterations):\n",
    "    ## Use model to estimate labels for unlabeled data\n",
    "    X_unlabeled = features[unlabeled_indices]\n",
    "    probs = model.predict_proba(X_unlabeled)\n",
    "    \n",
    "    ## Query strategy: select the sample with the highest uncertainty\n",
    "    ## For binary classification, this might be the closest to 0.5 in binary probs\n",
    "    ## We assume a binary classification (international vs travel history) which will be updated\n",
    "    uncertainty = np.max(probs, axis=1)\n",
    "    query_idx = np.argmax(uncertainty)\n",
    "    \n",
    "    ## Simulate querying a label for the selected sample\n",
    "    ## In a real application, this would involve obtaining the actual label for the sample\n",
    "    true_label = query_for_label(unlabeled_indices[query_idx])  ### Implement this function based on your application\n",
    "    \n",
    "    ## Update the training set with the newly labeled sample and retrain the model\n",
    "    X_train = np.vstack([X_train, X_unlabeled[query_idx]])\n",
    "    y_train = np.append(y_train, true_label)\n",
    "    \n",
    "    ## Remove the queried sample from the unlabeled pool\n",
    "    unlabeled_indices = np.delete(unlabeled_indices, query_idx)\n",
    "    \n",
    "    ## Retrain model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    ## Evaluate and print current model performance, if desired\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Iteration {iteration + 1}, accuracy: {accuracy_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a0cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels of unlabeled (no travel history) sequences\n",
    "\n",
    "## Extract features for unlabeled data\n",
    "X_unlabeled = features[unlabeled_indices]\n",
    "\n",
    "## Use the trained model to predict the labels of the unlabeled data\n",
    "predicted_labels = model.predict(X_unlabeled)\n",
    "\n",
    "## This task is a binary classification exercise which identifies unlabeled sequences as either\n",
    "## 'linked to the source' or 'not linked to the source'.\n",
    "## The model will output 0 (unlinked) or 1 (linked).\n",
    "\n",
    "## For illustration, let's map 0 to 'A' and 1 to 'X' (though in your case, 'Y' predictions remain 'Y')\n",
    "predicted_labels_mapped = np.where(predicted_labels == 0, 'unlinked', 'linked')\n",
    "\n",
    "## Attach these predictions back to your original dataset\n",
    "ids_unlabeled = combined_df.loc[unlabeled_indices, 'id'].values\n",
    "\n",
    "predicted_df = pd.DataFrame({\n",
    "    'id': ids_unlabeled,\n",
    "    'predicted_label': predicted_labels_mapped\n",
    "})\n",
    "\n",
    "print(predicted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f258f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarise predicted labels\n",
    "## Count the number of linked and unlinked observations in the predicted labels\n",
    "linked_count = (predicted_df['predicted_label'] == 'linked').sum()\n",
    "unlinked_count = (predicted_df['predicted_label'] == 'unlinked').sum()\n",
    "\n",
    "print(f\"Number of linked observations (predicted as 'with travel history'): {linked_count}\")\n",
    "print(f\"Number of unlinked observations (remaining as 'without travel history'): {unlinked_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
